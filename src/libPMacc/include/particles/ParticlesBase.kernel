/**
 * Copyright 2013-2017 Felix Schmitt, Heiko Burau, Rene Widera
 *
 * This file is part of libPMacc.
 *
 * libPMacc is free software: you can redistribute it and/or modify
 * it under the terms of either the GNU General Public License or
 * the GNU Lesser General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * libPMacc is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License and the GNU Lesser General Public License
 * for more details.
 *
 * You should have received a copy of the GNU General Public License
 * and the GNU Lesser General Public License along with libPMacc.
 * If not, see <http://www.gnu.org/licenses/>.
 */

#include "pmacc_types.hpp"
#include "particles/memory/boxes/ParticlesBox.hpp"
#include "particles/memory/boxes/PushDataBox.hpp"
#include "particles/memory/boxes/TileDataBox.hpp"
#include "dimensions/DataSpaceOperations.hpp"
#include "mappings/kernel/ExchangeMapping.hpp"
#include "particles/memory/boxes/ExchangePushDataBox.hpp"
#include "particles/memory/boxes/ExchangePopDataBox.hpp"
#include "memory/CtxArray.hpp"
#include "mappings/threads/ForEachIdx.hpp"
#include "mappings/threads/IdxConfig.hpp"

#include "particles/operations/Assign.hpp"
#include "particles/operations/Deselect.hpp"
#include "traits/NumberOfExchanges.hpp"
#include "nvidia/atomic.hpp"
#include "memory/shared/Allocate.hpp"
#include "memory/Array.hpp"

namespace PMacc
{

template<typename T_ParticleBox, typename T_SuperCellIdxType>
DINLINE typename T_ParticleBox::FramePtr
getPreviousFrameAndRemoveLastFrame( const typename T_ParticleBox::FramePtr& frame,
                                    T_ParticleBox& pb,
                                    const T_SuperCellIdxType& superCellIdx )
{
    typename T_ParticleBox::FramePtr result = pb.getPreviousFrame( frame );
    pb.removeLastFrame( superCellIdx );
    return result;
}

template< uint32_t T_worker >
struct KernelShiftParticles
{
    /*! This kernel move particles to the next supercell
     * This kernel can only run with a double checker board
     */
    template<class T_ParBox, class Mapping>
    DINLINE void operator()( T_ParBox pb, Mapping mapper ) const
    {
        typedef T_ParBox ParBox;
        typedef typename ParBox::FrameType FrameType;
        typedef typename ParBox::FramePtr FramePtr;

        const uint32_t dim = Mapping::Dim;
        const uint32_t frameSize = math::CT::volume<typename FrameType::SuperCellSize>::type::value;
        /* number exchanges in 2D=9 and in 3D=27 */
        const uint32_t numExchanges = traits::NumberOfExchanges<dim>::value;
        constexpr uint32_t numWorker = T_worker;

        /* define memory for two times Exchanges
         * index range [0,numExchanges-1] are being referred to as `low frames`
         * index range [numExchanges,2*numExchanges-1] are being referred to as `high frames`
         */
        PMACC_SMEM( destFrames, memory::Array< FramePtr, numExchanges * 2 > );
        //count particles per frame
        PMACC_SMEM( destFramesCounter, memory::Array< int, numExchanges > );

        PMACC_SMEM( frame, FramePtr );
        PMACC_SMEM( mustShift, bool );

        DataSpace<dim> superCellIdx = mapper.getSuperCellIndex( DataSpace<dim> (blockIdx) );
        const uint32_t workerIdx = threadIdx.x;

        using namespace mappings::threads;

        ForEachIdx<
            IdxConfig<
                1,
                numWorker
            >
        >{ workerIdx }(
            [&]( uint32_t const, uint32_t const )
            {
                mustShift = pb.getSuperCell( superCellIdx ).mustShift( );
                if ( mustShift )
                {
                    pb.getSuperCell( superCellIdx ).setMustShift( false );
                    frame = pb.getFirstFrame( superCellIdx );
                }
            }
        );

        __syncthreads( );
        if ( !mustShift || !frame.isValid( ) ) return;

        using ExchangeDomCfg = IdxConfig<
                numExchanges,
                numWorker
            >;

        memory::CtxArray< uint32_t, ExchangeDomCfg > lastFrameSizeCtx(0);

        memory::CtxArray< DataSpace<dim>, ExchangeDomCfg > relativeCtx(
            workerIdx,
            [&]( uint32_t const linearIdx, uint32_t const ) -> DataSpace<dim>{
                return superCellIdx + Mask::getRelativeDirections<dim> ( linearIdx + 1);
            }
        );

        ForEachIdx< ExchangeDomCfg > forEachExchange( workerIdx );

        /* if a partially filled last frame exists for the neighboring supercell,
         * each master thread (one master per direction) will load it
         */
        forEachExchange(
            [&]( uint32_t const linearIdx, uint32_t const idx )
            {
                destFramesCounter[linearIdx] = 0;
                destFrames[linearIdx] = FramePtr();
                destFrames[linearIdx + numExchanges] = FramePtr();
                /* load last frame of neighboring supercell */
                FramePtr tmpFrame(pb.getLastFrame( relativeCtx[idx] ));

                if ( tmpFrame.isValid() )
                {
                    lastFrameSizeCtx[idx] = pb.getSuperCell( relativeCtx[idx] ).getSizeLastFrame( );
                    // do not use the neighbor's last frame if it is full
                    if ( lastFrameSizeCtx[idx] < frameSize )
                    {
                        destFrames[linearIdx] = tmpFrame;
                        destFramesCounter[linearIdx] = lastFrameSizeCtx[idx];
                    }
                }
            }
        );

        __syncthreads( );

        /* iterate over the frame list of the current supercell */
        while ( frame.isValid() )
        {
            using ParticleDomCfg = IdxConfig<
                    numExchanges,
                    numWorker
                >;

            ForEachIdx< ParticleDomCfg > forEachParticle( workerIdx );

            memory::CtxArray< lcellId_t, ParticleDomCfg > destParticleIdxCtx( INV_LOC_IDX );
            memory::CtxArray< int, ParticleDomCfg > directionCtx;

            forEachParticle(
                [&]( uint32_t const linearIdx, uint32_t const idx )
                {
                    /* set to value to of multiMask to a value in range [-2, EXCHANGES - 1]
                     * -2 is no particle
                     * -1 is particle but it is not shifted (stays in supercell)
                     * >=0 particle moves in a certain direction
                     *     (@see ExchangeType in types.h)
                     */
                    directionCtx[idx] = frame[linearIdx][multiMask_] - 2;
                    if ( directionCtx[idx] >= 0 )
                    {
                        destParticleIdxCtx[idx] = atomicAdd( &(destFramesCounter[ directionCtx[idx] ]), 1 );
                    }
                }
            );
            __syncthreads( );

            forEachExchange(
                [&]( uint32_t const linearIdx, uint32_t const idx )
                {
                    /* If the master thread (responsible for a certain direction) did not
                     * obtain a `low frame` from the neighboring super cell before the loop,
                     * it will create one now.
                     *
                     * In case not all particles that are shifted to the neighboring
                     * supercell fit into the `low frame`, a second frame is created to
                     * contain further particles, the `high frame` (default: invalid).
                     */
                    if ( destFramesCounter[linearIdx] > 0 )
                    {
                        lastFrameSizeCtx[idx] = destFramesCounter[linearIdx];
                        /* if we had no `low frame` we load a new empty one */
                        if ( !destFrames[linearIdx].isValid() )
                        {
                            FramePtr tmpFrame(pb.getEmptyFrame( ));
                            destFrames[linearIdx] = tmpFrame;
                            pb.setAsLastFrame( tmpFrame, relativeCtx[idx] );
                        }
                        /* check if a `high frame` is needed */
                        if ( destFramesCounter[linearIdx] > frameSize )
                        {
                                lastFrameSizeCtx[idx] = destFramesCounter[linearIdx] - frameSize;
                                FramePtr tmpFrame(pb.getEmptyFrame( ));
                                destFrames[linearIdx + numExchanges] = tmpFrame;
                                pb.setAsLastFrame( tmpFrame, relativeCtx[idx] );
                        }
                    }
                }
            );
            __syncthreads( );

            forEachParticle(
                [&]( uint32_t const linearIdx, uint32_t const idx )
                {
                    /* All threads with a valid index in the neighbor's frame, valid index
                     * range is [0, frameSize * 2-1], will copy their particle to the new
                     * frame.
                     *
                     * The default value for indexes (in the destination frame) is
                     * above this range (INV_LOC_IDX) for all particles that are not shifted.
                     */
                    if ( destParticleIdxCtx[idx] < frameSize * 2 )
                    {
                        if ( destParticleIdxCtx[idx] >= frameSize )
                        {
                            /* use `high frame` */
                            directionCtx[idx] += numExchanges;
                            destParticleIdxCtx[idx] -= frameSize;
                        }
                        auto dstParticle = destFrames[ directionCtx[idx] ][ destParticleIdxCtx[idx] ];
                        auto srcParticle = frame[linearIdx];
                        dstParticle[multiMask_] = 1;
                        srcParticle[multiMask_] = 0;
                        auto dstFilteredParticle =
                                    particles::operations::deselect<multiMask>(dstParticle);
                        particles::operations::assign( dstFilteredParticle, srcParticle );
                    }
                }
            );
            __syncthreads( );

            forEachExchange(
                [&]( uint32_t const linearIdx, uint32_t const )
                {
                    /* if the `low frame` is now full, each master thread removes it and
                     * uses the `high frame` (is invalid, if still empty) as the next
                     * `low frame` for the following iteration of the loop
                     */
                    if ( destFramesCounter[linearIdx] >= frameSize )
                    {
                        destFramesCounter[linearIdx] -= frameSize;
                        destFrames[linearIdx] = destFrames[linearIdx + numExchanges];
                        destFrames[linearIdx + numExchanges] = FramePtr();
                    }
                    if ( linearIdx == 0 )
                    {
                        frame = pb.getNextFrame( frame );
                    }
                }
            );
            __syncthreads( );
        }

        forEachExchange(
            [&]( uint32_t const, uint32_t const idx )
            {
                /* each master thread updates the number of particles in the last frame
                 * of the neighbors supercell
                 */
                pb.getSuperCell( relativeCtx[idx] ).setSizeLastFrame( lastFrameSizeCtx[idx] );
            }
        );
    }
};

template< uint32_t T_worker >
struct KernelFillGapsLastFrame
{
    template<class ParBox, class Mapping>
    DINLINE void operator()( ParBox pb, Mapping mapper ) const
    {
        using namespace particles::operations;

        constexpr uint32_t frameSize = math::CT::volume<typename Mapping::SuperCellSize>::type::value;
        constexpr uint32_t dim = Mapping::Dim;
        constexpr uint32_t numWorker = T_worker;

        typedef typename ParBox::FramePtr FramePtr;

        DataSpace< dim > const superCellIdx = mapper.getSuperCellIndex( DataSpace< dim > (blockIdx) );

        PMACC_SMEM( lastFrame, FramePtr );

        PMACC_SMEM( gapIndices_sh, memory::Array< int, frameSize > );
        PMACC_SMEM( counterGaps, int);
        PMACC_SMEM( counterParticles, int);
        PMACC_SMEM( srcGap, int);

        const uint32_t workerIdx = threadIdx.x;

        using namespace mappings::threads;

        using MasterOnly = IdxConfig<
                1,
                numWorker
            >;

        ForEachIdx<
            MasterOnly
        >{ workerIdx }(
            [&]( uint32_t const, uint32_t const )
            {
                lastFrame = pb.getLastFrame( DataSpace< dim >( superCellIdx ) );
                counterGaps = 0;
                counterParticles = 0;
                srcGap = 0;
            }
        );

        __syncthreads( );

        if ( lastFrame.isValid( ) )
        {
            using ParticleDomCfg = IdxConfig<
                frameSize,
                numWorker
            >;

            /* context if a element within the frame is a particle */
            memory::CtxArray<
                bool,
                ParticleDomCfg
            >
            isParticleCtx(
                workerIdx,
                [&]( uint32_t const linearIdx, uint32_t const )
                {
                    return lastFrame[ linearIdx ][ multiMask_ ];
                }
            );

            /* loop over all particles in the frame */
            ForEachIdx< ParticleDomCfg > forEachParticle( workerIdx );

            //count particles in last frame
            forEachParticle(
                [&]( uint32_t const, uint32_t const idx )
                {
                    if( isParticleCtx[ idx ] )
                        nvidia::atomicAllInc( &counterParticles );
                }
            );

            __syncthreads( );

            forEachParticle(
                [&]( uint32_t const linearIdx, uint32_t const idx )
                {
                    if ( linearIdx < counterParticles && isParticleCtx[ idx ] == false )
                    {
                        const int localGapIdx = nvidia::atomicAllInc( &counterGaps );
                        gapIndices_sh[ localGapIdx ] = linearIdx;
                    }
                }
            );
            __syncthreads( );
            forEachParticle(
                [&]( uint32_t const linearIdx, uint32_t const idx )
                {
                    if ( linearIdx >= counterParticles && isParticleCtx[ idx ] )
                    {
                        //any particle search a gap
                        const int srcGapIdx = nvidia::atomicAllInc( &srcGap );
                        const int gapIdx = gapIndices_sh[ srcGapIdx ];
                        auto parDestFull = lastFrame[ gapIdx ];
                        /*enable particle*/
                        parDestFull[ multiMask_ ] = 1;
                        /* we not update multiMask because copy from mem to mem is to slow
                         * we have enabled particle explicit */
                        auto parDest = deselect< multiMask >( parDestFull );
                        auto parSrc = ( lastFrame[ linearIdx ] );
                        assign( parDest, parSrc );
                        parSrc[multiMask_] = 0; //delete old particle
                    }
                }
            );
        }
        ForEachIdx<
            MasterOnly
        >{ workerIdx }(
            [&]( uint32_t const, uint32_t const )
            {
                pb.getSuperCell( superCellIdx ).setSizeLastFrame( counterParticles );
            }
        );

    }
};

struct KernelFillGaps
{
    template<class ParBox, class Mapping>
    DINLINE void operator()( ParBox pb, Mapping mapper ) const
    {
        using namespace particles::operations;

        enum
        {
            TileSize = math::CT::volume<typename Mapping::SuperCellSize>::type::value,
            Dim = Mapping::Dim
        };

        typedef typename ParBox::FramePtr FramePtr;

        DataSpace<Dim> superCellIdx( mapper.getSuperCellIndex( DataSpace<Dim > (blockIdx) ) );

        //data copied from right (last) to left (first)
        PMACC_SMEM( firstFrame, FramePtr );
        PMACC_SMEM( lastFrame, FramePtr );

        PMACC_SMEM( particleIndices_sh, memory::Array< int, TileSize> );
        PMACC_SMEM( counterGaps, int );
        PMACC_SMEM( counterParticles, int );


        if ( threadIdx.x == 0 )
        {
            firstFrame = pb.getFirstFrame( DataSpace<Dim > (superCellIdx) );
            lastFrame = pb.getLastFrame( DataSpace<Dim > (superCellIdx) );
        }
        __syncthreads( );

        while ( firstFrame.isValid( ) && firstFrame != lastFrame )
        {

            if ( threadIdx.x == 0 )
            {
                //\todo: check if we need control thread or can write to shared with all threads
                counterGaps = 0;
                counterParticles = 0;
            }
            int localGapIdx = INV_LOC_IDX; //later we cann call localGapIdx < X because X<INV_LOC_IDX

            __syncthreads( );

            // find gaps
            if ( firstFrame[threadIdx.x][multiMask_] == 0 )
            {
                localGapIdx = nvidia::atomicAllInc( &counterGaps );
            }
            __syncthreads( );

            if ( counterGaps == 0 )
            {
                if ( threadIdx.x == 0 )
                {
                    firstFrame = pb.getNextFrame( firstFrame );
                }
                __syncthreads( ); //wait control thread search new frame
                continue; //check next frame
            }

            // search particles for gaps
            if ( lastFrame[threadIdx.x][multiMask_] == 1 )
            {
                int localParticleIdx = nvidia::atomicAllInc( &counterParticles );
                particleIndices_sh[localParticleIdx] = threadIdx.x;
            }
            __syncthreads( );
            if ( localGapIdx < counterParticles )
            {
                const int parIdx = particleIndices_sh[localGapIdx];
                auto parDestFull = (firstFrame[threadIdx.x]);
                /*enable particle*/
                parDestFull[multiMask_] = 1;
                /* we not update multiMask because copy from mem to mem is to slow
                 * we have enabled particle explicit */
                auto parDest = deselect<multiMask>(parDestFull);
                auto parSrc = (lastFrame[parIdx]);
                assign( parDest, parSrc );
                parSrc[multiMask_] = 0;
            }
            __syncthreads( );
            if ( threadIdx.x == 0 )
            {
                if ( counterGaps < counterParticles )
                {
                    //any gap in the first frame is filled
                    firstFrame = pb.getNextFrame( firstFrame );
                }
                else if ( counterGaps > counterParticles )
                {
                    //we need more particles
                    lastFrame = getPreviousFrameAndRemoveLastFrame( lastFrame, pb, superCellIdx );
                }
                else if ( counterGaps == counterParticles )
                {
                    lastFrame = getPreviousFrameAndRemoveLastFrame( lastFrame, pb, superCellIdx );
                    if ( lastFrame.isValid( ) && lastFrame != firstFrame )
                    {
                        firstFrame = pb.getNextFrame( firstFrame );
                    }
                }
            }
            __syncthreads( );
        }
    }
};

struct KernelDeleteParticles
{
    template< class T_ParticleBox, class Mapping>
    DINLINE void operator()(
        T_ParticleBox pb,
        Mapping mapper
    ) const
    {
        using namespace particles::operations;

        typedef T_ParticleBox ParticleBox;
        typedef typename ParticleBox::FrameType FrameType;
        typedef typename ParticleBox::FramePtr FramePtr;

        enum
        {
            Dim = Mapping::Dim
        };

        DataSpace<Dim> superCellIdx = mapper.getSuperCellIndex( DataSpace<Dim > (blockIdx) );
        const int linearThreadIdx = threadIdx.x;

        PMACC_SMEM( frame, FramePtr );

        if ( linearThreadIdx == 0 )
        {
            frame = pb.getLastFrame( superCellIdx );
        }

        __syncthreads( );

        while ( frame.isValid( ) )
        {

            auto particle = (frame[linearThreadIdx]);
            particle[multiMask_] = 0; //delete particle

            __syncthreads( );

            if ( linearThreadIdx == 0 )
            {
                //always remove the last frame
                frame = getPreviousFrameAndRemoveLastFrame( frame, pb, superCellIdx );
            }
            __syncthreads( );
        }

        if ( linearThreadIdx == 0 )
            pb.getSuperCell( superCellIdx ).setSizeLastFrame( 0 );

    }
};

struct KernelBashParticles
{
    template< class ParBox, class BORDER, class Mapping>
    DINLINE void operator()(
        ParBox pb,
        ExchangePushDataBox<vint_t, BORDER, Mapping::Dim - 1 > border,
        Mapping mapper ) const
    {
        using namespace particles::operations;

        enum
        {
            TileSize = math::CT::volume<typename Mapping::SuperCellSize>::type::value,
            Dim = Mapping::Dim
        };
        typedef typename ParBox::FramePtr FramePtr;

        DataSpace<Dim> superCellIdx = mapper.getSuperCellIndex( DataSpace<Dim > (blockIdx) );

        PMACC_SMEM( numBashedParticles, int );
        PMACC_SMEM( frame, FramePtr );
        PMACC_SMEM( hasMemory, bool );
        PMACC_SMEM( tmpBorder, TileDataBox<BORDER> );

        if ( threadIdx.x == 0 )
        {
            hasMemory = true;
            frame = pb.getLastFrame( superCellIdx );
        }
        //\todo: eventuell ist es schneller, parallelen und seriellen Code zu trennen
        __syncthreads( );
        while ( frame.isValid( ) && hasMemory )
        {
            lcellId_t bashIdx = INV_LOC_IDX;
            if ( threadIdx.x == 0 )
                numBashedParticles = 0;
            __syncthreads( );

            if ( frame[threadIdx.x][multiMask_] == 1 )
            {
                bashIdx = nvidia::atomicAllInc( &numBashedParticles );
            }
            __syncthreads( );

            if ( numBashedParticles > 0 )
            {

                if ( threadIdx.x == 0 )
                {
                    // DataSpaceOperations<DIM2>::reduce computes target position for domainTile and exchangeType
                    tmpBorder = border.pushN( numBashedParticles,
                                              DataSpaceOperations<Dim>::reduce(
                                                                                superCellIdx,
                                                                                mapper.getExchangeType( ) ) );
                    if ( tmpBorder.getSize( ) < numBashedParticles )
                        hasMemory = false;
                }
                __syncthreads( );

                if ( bashIdx != INV_LOC_IDX && bashIdx < tmpBorder.getSize( ) )
                {
                    auto parDest = tmpBorder[bashIdx][0];
                    auto parSrc = (frame[threadIdx.x]);
                    assign( parDest, parSrc );
                    parSrc[multiMask_] = 0;
                }
                __syncthreads( );

                if ( threadIdx.x == 0 && hasMemory )
                {
                    //always remove the last frame
                    frame = getPreviousFrameAndRemoveLastFrame( frame, pb, superCellIdx );
                }
            }
            else
            {
                //if we had no particles to copy than we are the last and only frame
                if ( threadIdx.x == 0 )
                {
                    frame = getPreviousFrameAndRemoveLastFrame( frame, pb, superCellIdx );
                }
            }
            __syncthreads( );
        }
        if ( threadIdx.x == 0 )
            pb.getSuperCell( superCellIdx ).setSizeLastFrame( 0 );

    }
};


struct KernelInsertParticles
{
    template<class ParBox, class BORDER, class Mapping>
    DINLINE void operator()( ParBox pb,
                                           ExchangePopDataBox<vint_t, BORDER, Mapping::Dim - 1 > border,
                                           Mapping mapper ) const
    {

        using namespace particles::operations;

        enum
        {
            TileSize = math::CT::volume<typename Mapping::SuperCellSize>::type::value,
            Dim = Mapping::Dim
        };

        typedef typename ParBox::FramePtr FramePtr;
        PMACC_SMEM( frame, FramePtr );
        PMACC_SMEM( elementCount, int );
        PMACC_SMEM( tmpBorder, TileDataBox<BORDER> );


        DataSpace < Mapping::Dim - 1 > superCell;

        if ( threadIdx.x == 0 )
        {
            tmpBorder = border.get(blockIdx.x,superCell);
            elementCount = tmpBorder.getSize( );
            if ( elementCount > 0 )
            {
                frame = pb.getEmptyFrame( );
            }
        }
        __syncthreads( );
        if ( threadIdx.x < elementCount )
        {
            auto parDestFull = (frame[threadIdx.x]);
            parDestFull[multiMask_] = 1;
            auto parSrc = ((tmpBorder[threadIdx.x])[0]);
            /*we know that source has no multiMask*/
            auto parDest = deselect<multiMask>(parDestFull);
            assign( parDest, parSrc );
        }
        /*if this syncronize fix the kernel crash in spezial cases,
         * I can't tell why.
         */
        __syncthreads( );
        if ( (threadIdx.x == 0) && (elementCount > 0) )
        {
            // compute the super cell position in target frame to insert into
            ///\todo: offset == simulation border should be passed to this func instead of being created here
            DataSpace<Dim> dstSuperCell = DataSpaceOperations < Dim - 1 > ::extend( superCell,
                                                                                    mapper.getExchangeType( ),
                                                                                    mapper.getGridSuperCells( ),
                                                                                    DataSpace<Dim>::create( mapper.getGuardingSuperCells( ) ) );

            pb.setAsLastFrame( frame, dstSuperCell );
        }


    }
};


} //namespace PMacc
