/* Copyright 2013-2019 Heiko Burau, Rene Widera
 *
 * This file is part of PIConGPU.
 *
 * PIConGPU is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * PIConGPU is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with PIConGPU.
 * If not, see <http://www.gnu.org/licenses/>.
 */

#pragma once

#include "picongpu/fields/MaxwellSolver/DirSplitting/DirSplitting.hpp"
#include <pmacc/types.hpp>
#include <pmacc/math/vector/Float.hpp>
#include <pmacc/math/Vector.hpp>
#include <pmacc/cuSTL/container/compile-time/SharedBuffer.hpp>
#include <pmacc/cuSTL/algorithm/cudaBlock/Foreach.hpp>
#include <pmacc/cuSTL/cursor/tools/twistVectorFieldAxes.hpp>
#include <pmacc/nvidia/functors/Assign.hpp>


namespace picongpu
{
namespace fields
{
namespace maxwellSolver
{

template<uint32_t pass, typename BlockDim, typename JSpaceTwist>
struct DirSplittingKernel
{
    using result_type = void;

    typedef typename pmacc::math::CT::make_Vector<
        simDim,
        bmpl::integral_c<int,0>
    >::type ZeroVector;

    typedef typename pmacc::math::CT::Assign<
        ZeroVector,
        bmpl::integral_c<int,0>,
        bmpl::integral_c<int,-1>
    >::type Minus;

    typedef typename pmacc::math::CT::Assign<
        ZeroVector,
        bmpl::integral_c<int,0>,
        bmpl::integral_c<int,1>
    >::type Plus;

    PMACC_ALIGN(totalLength,int);
    DirSplittingKernel(int totalLength) : totalLength(totalLength) {}

    template<typename CursorE, typename CursorB, typename CursorJ, typename RCursorE, typename RCursorB >
    DINLINE void propagate(CursorE cursorE, CursorB cursorB, CursorJ cursorJ, RCursorE r_cursorE, RCursorB r_cursorB) const
    {
        typedef typename pmacc::math::CT::AssignIfInRange<
            ZeroVector,
            bmpl::integral_c<int,JSpaceTwist::y::value>,
            bmpl::integral_c<int,1>
        >::type jYDir;

        typedef typename pmacc::math::CT::AssignIfInRange<
            ZeroVector,
            bmpl::integral_c<int,JSpaceTwist::z::value>,
            bmpl::integral_c<int,1>
        >::type jZDir;

        const float_X deltaT = DELTA_T;
        const float_X constJE = (float_X(0.5)  / EPS0) * deltaT;

        const auto minus = Minus::toRT();
        const auto plus = Plus::toRT();
        float a_plus = (*cursorB(minus)).z() + (*cursorE(minus)).y();
        float a_minus = (*cursorB(plus)).z() - (*cursorE(plus)).y();
        float a_prime_plus = (*cursorB(minus)).y() - (*cursorE(minus)).z();
        float a_prime_minus = (*cursorB(plus)).y() + (*cursorE(plus)).z();

        __syncthreads();

        (*cursorB).z() = 0.5f * (a_plus + a_minus); //if I enable the double buffer I need to ad += instead of =
        (*cursorE).y() = 0.5f * (a_plus - a_minus);
        (*cursorB).y() = 0.5f * (a_prime_plus + a_prime_minus);
        (*cursorE).z() = 0.5f * (a_prime_minus - a_prime_plus);
	    (*cursorE).x() -= 0.5f * ( (*cursorJ).x() + (*cursorJ(jYDir::toRT())).x() +  (*cursorJ(jZDir::toRT())).x() + (*cursorJ(jYDir::toRT() + jZDir::toRT())).x()) * constJE * (pass==1?float_X(0.5):float_X(1.0));

        __syncthreads();
    }

    template<typename CursorE, typename CursorB, typename CursorJ, typename T_Acc >
    DINLINE void operator()(T_Acc const & acc, CursorE globalE, CursorB globalB,CursorJ globalJ, CursorE old_globalE, CursorB old_globalB) const
    {

        typedef typename pmacc::math::CT::Assign<
            ZeroVector,
            bmpl::integral_c<int,0>,
            bmpl::integral_c<int,2>
        >::type XEntend;

        /* extend x size with 2 guards
         *
         * \todo: optimize cache size
         */
        typedef typename pmacc::math::CT::add<
            BlockDim,
            XEntend>::type CacheSize;

        typedef container::CT::SharedBuffer<float3_X, CacheSize, 0 > CacheE;
        typedef container::CT::SharedBuffer<float3_X, CacheSize, 1 > CacheB;
        CacheE cacheE( acc );
        CacheB cacheB( acc );

        float3_X fieldE_old;
        float3_X fieldB_old;
        const DataSpace<simDim> threadIndex(threadIdx);
        int threadPos_x = threadIndex.x();

        //!@todo remove this explicit index calculation, this is a workaround during the lockstep refactoring
        int linearThreadIdx = threadIdx.z * BlockDim::x::value * BlockDim::y::value +
            threadIdx.y * BlockDim::x::value +
            threadIdx.x;
        algorithm::cudaBlock::Foreach<BlockDim> foreach(linearThreadIdx);
        for(int x_offset = 0; x_offset < this->totalLength; x_offset += BlockDim::x::value)
        {
            auto globalShift = DataSpace<simDim>::create(0);
            globalShift.x() = -1 + x_offset;

            foreach(acc, CacheE::Zone(), cacheE.origin(), globalE(globalShift), pmacc::nvidia::functors::Assign{});
            foreach(acc, CacheB::Zone(), cacheB.origin(), globalB(globalShift), pmacc::nvidia::functors::Assign{});
            __syncthreads();

            const auto minus = Minus::toRT();
            const auto plus = Plus::toRT();

            DataSpace<simDim> cursorShift(plus);
            cursorShift.x()+=threadPos_x;

            for(uint32_t d = 1;d < simDim; ++d)
                cursorShift[d]+=threadIndex[d];

            auto cursorE = cacheE.origin()(cursorShift);
            auto cursorB = cacheB.origin()(cursorShift);

            if(threadPos_x == BlockDim::x::value - 1)
            {
                fieldE_old = *cursorE;
                fieldB_old = *cursorB;
            }
            if(threadPos_x == 0 && x_offset > 0)
            {
                *cursorE(minus) = fieldE_old;
                *cursorB(minus) = fieldB_old;
            }

            propagate(cursorE, cursorB, globalJ(globalShift+cursorShift),globalE(globalShift+cursorShift),globalB(globalShift+cursorShift));
            //propagate(cursorE, cursorB, globalJ(globalShift+cursorShift),old_globalE(globalShift+cursorShift),old_globalB(globalShift+cursorShift));

            DataSpace<simDim> globalShiftTmp;
            globalShiftTmp.x() = x_offset;

            typedef zone::CT::SphericZone<BlockDim> BlockZone;
            foreach(acc, BlockZone(), globalE(globalShiftTmp), cacheE.origin()(plus), pmacc::nvidia::functors::Assign{});
            foreach(acc, BlockZone(), globalB(globalShiftTmp), cacheB.origin()(plus), pmacc::nvidia::functors::Assign{});

            __syncthreads();

            threadPos_x = BlockDim::x::value - 1 - threadPos_x;
        }
    }

};

} // namespace maxwellSolver
} // namespace fields
} // namespace picongpu
